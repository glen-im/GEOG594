{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER\n",
    "- Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cytoolz import take, concat\n",
    "from random import sample\n",
    "from collections import Counter\n",
    "\n",
    "# pd.set_option('max_colwidth', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read corpus of news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_msgpack('https://www.dropbox.com/s/0oqem0qa6oiz02r/articles.msg?dl=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load spaCy parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3565"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_text = []\n",
    "for i in df['text']:\n",
    "    len_text.append(len(i))\n",
    "\n",
    "len_text[len(i) == max(len_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df['text'].iloc[3565])\n",
    "# doc = nlp(df.loc[3565]['text']) \n",
    "# different???????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\"></br> \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    The European Parliament's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " environment committee is expected on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to call for an action programme to improve water quality in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the European Union\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and a legally binding framework directive. </br> Opting for this \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-pronged strategy would enable the parliament to overcome its dilemma over whether to push for an action programme or a directive. </br> A programme would allow the assembly more say in drawing up the legislation but the final text would be less specifically binding on the member states than a directive. </br> Rapporteur Karl-Heinz Florenz believes \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " solution would be for \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the European Commission\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to formulate a coherent overall policy for \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " water resources setting out the major objectives and the actions needed to achieve them. </br> In a report expected to be adopted by the environmental committee, the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    German\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Christian Democrat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " suggests that \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " ministers and the parliament should adopt this overall policy in the form of an action programme which includes explicit implementing measures. </br> The Commission should then come up with a proposal for a water resources framework directive which converts this overall strategy into a legally-binding directive, the draft report says. </br> Among the recommendations the committee is expected to make are a call for the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " not to dilute its policies on water protection, which recent \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Commission\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " reports show is deteriorating. </br> In particular, \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Euro-\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "MPs are likely to criticise the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Commission\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "'s communication on \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " water policy - COM(96)59 - for disregarding \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " treaty references to the need to respect the precautionary principle. </br> This means \"such substantive requirements as emission standards and quality objectives are largely abandoned,\" according to \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Florenz\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "'s report. </br> The environment committee is due on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Wednesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to adopt reports on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \"daughter directives\" on water policy. One concerns the quality of drinking water -- COM(94)612 -- the other \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Europe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "'s bathing waters -- COM(94)36. \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply spaCy NER to news corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['doc'] = list(nlp.pipe(df['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate news stories by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week\n",
       "1996-08-19/1996-08-25    600\n",
       "1996-08-26/1996-09-01    700\n",
       "1996-09-02/1996-09-08    700\n",
       "1996-09-09/1996-09-15    700\n",
       "1996-09-16/1996-09-22    700\n",
       "1996-09-23/1996-09-29    700\n",
       "1996-09-30/1996-10-06    700\n",
       "1996-10-07/1996-10-13    700\n",
       "1996-10-14/1996-10-20    700\n",
       "1996-10-21/1996-10-27    700\n",
       "1996-10-28/1996-11-03    700\n",
       "1996-11-04/1996-11-10    700\n",
       "1996-11-11/1996-11-17    700\n",
       "1996-11-18/1996-11-24    700\n",
       "1996-11-25/1996-12-01    700\n",
       "1996-12-02/1996-12-08    700\n",
       "1996-12-09/1996-12-15    700\n",
       "1996-12-16/1996-12-22    700\n",
       "1996-12-23/1996-12-29    700\n",
       "1996-12-30/1997-01-05    200\n",
       "Freq: W-SUN, Name: doc, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['week'] = df['date'].dt.to_period('W')\n",
    "df.groupby('week')['doc'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find most often mentions PERSON names / week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_persons(docs, k=5):\n",
    "    freq = Counter(filter(None, (e.orth_.strip()\n",
    "                                for d in docs\n",
    "                                for e in d.ents if e.label_ == 'PERSON')))\n",
    "    return freq.most_common(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Clinton', 43), ('Lebed', 33), ('Netanyahu', 19), ('Yeltsin', 18), ('M4', 12)]\n",
      "[('Clinton', 66), ('Lebed', 36), ('Yeltsin', 33), ('Arafat', 27), ('Netanyahu', 26)]\n",
      "[('Clinton', 56), ('Yeltsin', 51), ('Okinawa', 29), ('Saddam', 27), ('Tyson', 26)]\n",
      "[('Clinton', 68), ('Bossi', 38), ('Saddam', 36), ('Netanyahu', 30), ('Saddam Hussein', 25)]\n",
      "[('Yeltsin', 36), ('Clinton', 33), ('Banharn', 31), ('Dole', 18), ('Perry', 18)]\n",
      "[('Yeltsin', 70), ('Clinton', 54), ('Arafat', 41), ('Netanyahu', 37), ('Rubin', 26)]\n",
      "[('Clinton', 91), ('Dole', 59), ('Netanyahu', 32), ('Abdullah', 31), ('Arafat', 28)]\n",
      "[('Dole', 52), ('Clinton', 50), ('M4', 37), ('Arafat', 21), ('Netanyahu', 18)]\n",
      "[('Clinton', 71), ('Dole', 62), ('Netanyahu', 26), ('Arafat', 26), ('Lebed', 23)]\n",
      "[('Clinton', 45), ('Lee', 35), ('Chirac', 26), ('Avg', 16), ('Barzani', 15)]\n",
      "[('Clinton', 64), ('Dole', 52), ('AGM', 28), ('Bill Clinton', 23), ('Rabin', 20)]\n",
      "[('Clinton', 88), ('Bhutto', 32), ('Yeltsin', 31), ('Kohl', 22), ('Bill Clinton', 21)]\n",
      "[('Castro', 38), ('Yeltsin', 31), ('FORECAST', 24), ('Interim', 24), ('Clinton', 21)]\n",
      "[('Clinton', 76), ('Lukashenko', 68), ('FORECAST', 38), ('Sampras', 26), ('Graf', 21)]\n",
      "[('Clinton', 31), ('Yeltsin', 30), ('Fokker', 29), ('Milosevic', 18), ('Lukashenko', 17)]\n",
      "[('Greenspan', 53), ('Clinton', 49), ('Milosevic', 41), ('Alan Greenspan', 25), ('Zajedno', 20)]\n",
      "[('AGM', 48), ('Clinton', 29), ('Jewell', 19), ('Milosevic', 19), ('Annan', 18)]\n",
      "[('Clinton', 36), ('Fujimori', 36), ('Arafat', 22), ('Videnov', 20), ('Mastroianni', 19)]\n",
      "[('Yeltsin', 40), ('Milosevic', 40), ('Netanyahu', 32), ('Fujimori', 28), ('Alberto Fujimori', 17)]\n",
      "[('Netanyahu', 10), ('Gingrich', 9), ('Arafat', 8), ('Williams', 7), ('Tung', 6)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "week\n",
       "1996-08-19/1996-08-25    [(Clinton, 43), ...\n",
       "1996-08-26/1996-09-01    [(Clinton, 66), ...\n",
       "1996-09-02/1996-09-08    [(Clinton, 56), ...\n",
       "1996-09-09/1996-09-15    [(Clinton, 68), ...\n",
       "1996-09-16/1996-09-22    [(Yeltsin, 36), ...\n",
       "1996-09-23/1996-09-29    [(Yeltsin, 70), ...\n",
       "1996-09-30/1996-10-06    [(Clinton, 91), ...\n",
       "1996-10-07/1996-10-13    [(Dole, 52), (Cl...\n",
       "1996-10-14/1996-10-20    [(Clinton, 71), ...\n",
       "1996-10-21/1996-10-27    [(Clinton, 45), ...\n",
       "1996-10-28/1996-11-03    [(Clinton, 64), ...\n",
       "1996-11-04/1996-11-10    [(Clinton, 88), ...\n",
       "1996-11-11/1996-11-17    [(Castro, 38), (...\n",
       "1996-11-18/1996-11-24    [(Clinton, 76), ...\n",
       "1996-11-25/1996-12-01    [(Clinton, 31), ...\n",
       "1996-12-02/1996-12-08    [(Greenspan, 53)...\n",
       "1996-12-09/1996-12-15    [(AGM, 48), (Cli...\n",
       "1996-12-16/1996-12-22    [(Clinton, 36), ...\n",
       "1996-12-23/1996-12-29    [(Yeltsin, 40), ...\n",
       "1996-12-30/1997-01-05    [(Netanyahu, 10)...\n",
       "Freq: W-SUN, Name: doc, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('week')['doc'].apply(get_top_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(., 'PUNCT', '.', False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-2], doc[-2].pos_, doc[-2].lemma_, doc[-2].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['environment committee',\n",
       " 'action programme',\n",
       " 'water quality',\n",
       " 'binding framework directive',\n",
       " 'pronged strategy',\n",
       " 'its dilemma',\n",
       " 'action programme',\n",
       " 'final text',\n",
       " 'member states',\n",
       " 'coherent overall policy',\n",
       " 'water resources',\n",
       " 'major objectives',\n",
       " 'environmental committee',\n",
       " 'overall policy',\n",
       " 'overall strategy',\n",
       " 'draft report',\n",
       " 'its policies',\n",
       " 'water protection',\n",
       " 'water policy',\n",
       " 'treaty references',\n",
       " 'precautionary principle',\n",
       " 'such substantive requirements',\n",
       " 'emission standards',\n",
       " 'quality objectives',\n",
       " 'environment committee',\n",
       " 'daughter directives',\n",
       " 'water policy',\n",
       " 'drinking water',\n",
       " 'bathing waters']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_terms(doc):                         # to spot ANN followed by V\n",
    "    terms = []\n",
    "    start = --1                             #start will be the token # where the sequnce(Adj.) started. will be from -1, that we haven't seen yet.\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i].pos_ in ['NOUN', 'ADJ']:  # if it's N or adj,\n",
    "            if start == -1:                 #no marked as a start of something yet,\n",
    "                start = i\n",
    "                #else: do nothing\n",
    "        else:                               #if we are at the end? or at the start\n",
    "            if start != -1 and i > start + 1 and doc[i-1].pos_ == 'NOUN' and not doc[i-1].is_stop:\n",
    "                #and the preceding word is N\n",
    "                terms.append(doc[start:i].lower_) #then we take the subpart and lowercase and added to terms\n",
    "            start = -1\n",
    "    if start != -1 and i > start + 1 and doc[i-1].is_stop:\n",
    "        #we also need to check if we are at the end of the sentence\n",
    "        terms.append(doc[start:].lower_)\n",
    "    return terms\n",
    "\n",
    "get_terms(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['doc'] = list(nlp.pipe(df['text']))\n",
    "df['terms'] = df['doc'].apply(get_terms)\n",
    "freq = Counter(concat(df['terms']))\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check out individual users' frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('last week', 861), ('last year', 735), ('next year', 572), ('central bank', 535), ('news conference', 477), ('interest rates', 400), ('first time', 363), ('last month', 362), ('first half', 344), ('third quarter', 308)]\n"
     ]
    }
   ],
   "source": [
    "print(freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-c5c59e83dae5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   6663\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   6664\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6665\u001b[1;33m                        observed=observed, **kwargs)\n\u001b[0m\u001b[0;32m   6666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    597\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                     \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m   3289\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3290\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3291\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3292\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3293\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'author'"
     ]
    }
   ],
   "source": [
    "top = df.groupby('author')['text'] \\\n",
    "        .count() \\\n",
    "        .sort_values(ascending=False)\n",
    "top.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in top.head(10).index:\n",
    "    #as we are interested in not numbers but who(index)\n",
    "    print('---', name)\n",
    "    subset = df['author'] == name\n",
    "    freq = Counter(concat(df[subset]['terms']))\n",
    "    # take the terms column out, then make all comments into 1, then count freq\n",
    "    print(', '.join(t for t, f in freq.most_common(50)))\n",
    "    # each of the term, freq pairs, I will take only the term\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in top.head(10).index:\n",
    "    print('---', name)\n",
    "    subset = df['author'] == name\n",
    "    freq = pd.DataFrame({'all':\n",
    "                        Counter(concat(df['terms'])),\n",
    "                        'user':\n",
    "                        Counter(concat(df[subset]['terms']))})\n",
    "    freq['pmi'] = np.log2((freq['user'] * np.sum(freq['all'])) / \n",
    "                         (freq['all'] * np.sum(freq['user'])))\n",
    "    print('\\n '.join(freq[freq['user']>5]\n",
    "                  .sort_values('pmi', ascending=False)\n",
    "                  .head(10)\n",
    "                  .index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out some if not interested in, as if it's not real people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['author'].isin(['Author1', 'Author2'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> resorting after filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df.groupby('author')['text'] \\\n",
    "        .count() \\\n",
    "        .sort_values(ascending=False)\n",
    "top.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### visualize posting frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top.head(50).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### % of comments from top X authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round((sum(top.head(50)) / sum(top) * 100), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> % of comments from 1 posting users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round((sum(top == 1) / len(top) * 100)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> tokenize comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TweetTokenizer(perserve_case = False,\n",
    "                  reduce_len = True,\n",
    "                  strip_handles = True)\n",
    "df['tokens'] = df['text'].apply(T.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find keywords for top 10 authors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
